{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_image(image):\n",
    "    if(image is not None):\n",
    "        width = image.shape[1]\n",
    "        height = image.shape[0]\n",
    "        with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = hands.process(image)\n",
    "            image.flags.writeable = True\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                    hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                    # Check if the hand bounding box is valid\n",
    "                    if hand_bbox[2] > 0 and hand_bbox[3] > 0:\n",
    "                        # Extract hand image\n",
    "                        hand_image = image[hand_bbox[1]:hand_bbox[1] + hand_bbox[3], hand_bbox[0]:hand_bbox[0] + hand_bbox[2]]\n",
    "                        # Check if hand_image is not empty\n",
    "                        if hand_image.size != 0:\n",
    "                            # Resize hand image\n",
    "                            hand_image = cv2.resize(hand_image, (64, 64))\n",
    "                            return hand_image\n",
    "                        else:\n",
    "                            print(\"Error: Empty hand image\")\n",
    "                    else:\n",
    "                        print(\"Error: Invalid hand bounding box\")\n",
    "            else:\n",
    "                print(\"Error: No hand detected\")\n",
    "        # Return None if no hand image is found\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_of_frames(vidPath):\n",
    "    sequence = []\n",
    "    seq_len = 30\n",
    "    \n",
    "    vid = cv2.VideoCapture(vidPath)\n",
    "    total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"There are {} frames to be processed \".format(total_frames))\n",
    "    buffer = np.zeros((64, 64,3))\n",
    "    # Determine the step size to select frames evenly\n",
    "    step = max(total_frames // seq_len, 1)\n",
    "    for frame_num in range(0, total_frames, step):\n",
    "        vid.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        _, frame = vid.read()\n",
    "\n",
    "        hand_frame = get_hand_image(frame)\n",
    "        # plt.imshow(hand_frame,cmap='gray')\n",
    "\n",
    "        if hand_frame is None:\n",
    "            sequence.append(buffer/255)\n",
    "        else:\n",
    "            sequence.append(hand_frame / 255)\n",
    "            buffer = hand_frame\n",
    "    # Apply pre-padding if necessary\n",
    "    while len(sequence) < seq_len:\n",
    "        sequence.append(buffer / 255)\n",
    "    \n",
    "    vid.release()\n",
    "    return sequence[:seq_len] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_seq_of_frames(r\"C:\\Users\\Rommel\\OneDrive\\Pictures\\Camera Roll\\WIN_20240330_13_58_23_Pro.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_seq_of_frames(vidPath):\n",
    "#     sequence = []\n",
    "#     vid = cv2.VideoCapture(vidPath)\n",
    "#     total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print(\"There are {} frames to be processed \".format(total_frames))\n",
    "#     for frame_num in range(total_frames):\n",
    "#         if(frame_num % 5 != 0):\n",
    "#             continue\n",
    "#         vid.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "#         _ , frame = vid.read()\n",
    "#         frame.resize(64,64,3)\n",
    "#         print(\"Processing frame {}\".format(frame_num))\n",
    "#         sequence.append(frame/255)\n",
    "#         # cv2.imwrite('{}/{}.png'.format(vidPath[5:-4],frame_num), frame)\n",
    "#         if(frame_num > 45):\n",
    "#             break\n",
    "#     vid.release()\n",
    "#     return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_seq_of_frames(vidPath):\n",
    "#     sequence = []\n",
    "#     seq_len = 30\n",
    "#     vid = cv2.VideoCapture(vidPath)\n",
    "#     total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print(\"There are {} frames to be processed \".format(total_frames))\n",
    "    \n",
    "#     # Determine the step size to select frames evenly\n",
    "#     step = max(total_frames // seq_len, 1)\n",
    "    \n",
    "#     for frame_num in range(0, total_frames, step):\n",
    "#         vid.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "#         _, frame = vid.read()\n",
    "#         frame = cv2.resize(frame, (64, 64))\n",
    "#         # print(\"Processing frame {}\".format(frame_num))\n",
    "#         sequence.append(frame / 255)\n",
    "    \n",
    "#     # Apply pre-padding if necessary\n",
    "#     while len(sequence) < seq_len:\n",
    "#         sequence.insert(0, np.zeros((64, 64, 3)))\n",
    "    \n",
    "#     vid.release()\n",
    "#     return sequence[:seq_len]  # Ensure the returned sequence has a maximum length of 12 frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(parentFolder,dataset):\n",
    "    for file in os.listdir(parentFolder):\n",
    "        filePath = \"{}/{}\".format(parentFolder,file)\n",
    "        print(\"Processing \" + filePath)\n",
    "        dataset.append(create_seq_of_frames(filePath))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/20240330_180851.mp4\n",
      "There are 49 frames to be processed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/20240330_180908.mp4\n",
      "There are 44 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/20240330_180911.mp4\n",
      "There are 48 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/20240330_180914.mp4\n",
      "There are 40 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/20240330_180923.mp4\n",
      "There are 46 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/VID20240330225840.mp4\n",
      "There are 57 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct/VID20240330225910.mp4\n",
      "There are 23 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/20240330_180854.mp4\n",
      "There are 63 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/20240330_180901.mp4\n",
      "There are 38 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/20240330_180904.mp4\n",
      "There are 40 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/20240330_180917.mp4\n",
      "There are 57 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/VID20240330225852.mp4\n",
      "There are 36 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/VID20240330225856.mp4\n",
      "There are 24 frames to be processed \n",
      "Processing D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect/VID20240330225900.mp4\n",
      "There are 95 frames to be processed \n"
     ]
    }
   ],
   "source": [
    "x = create_dataset(r\"D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\correct\",x)\n",
    "x = create_dataset(r\"D:\\Projects\\Codeshastra_ByteMe\\Bodhi\\Testing data\\incorrect\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ['correct'] * 7 + ['incorrect'] * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"features\":x,\n",
    "    \"labels\":y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_dataset.pkl','wb') as f:\n",
    "    pickle.dump(dataset,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
