{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box (501, 89, 105, 254)\n",
      "Bounding Box (498, 95, 110, 260)\n",
      "Bounding Box (480, 99, 106, 259)\n",
      "Bounding Box (472, 98, 105, 261)\n",
      "Bounding Box (470, 98, 108, 266)\n",
      "Bounding Box (461, 97, 108, 268)\n",
      "Bounding Box (458, 98, 110, 268)\n",
      "Bounding Box (451, 100, 108, 263)\n",
      "Bounding Box (449, 98, 109, 267)\n",
      "Bounding Box (443, 103, 103, 255)\n",
      "Bounding Box (438, 99, 107, 258)\n",
      "Bounding Box (438, 98, 107, 260)\n",
      "Bounding Box (436, 101, 105, 258)\n",
      "Bounding Box (436, 101, 105, 255)\n",
      "Bounding Box (433, 109, 103, 254)\n",
      "Bounding Box (433, 107, 103, 254)\n",
      "Bounding Box (433, 116, 100, 250)\n",
      "Bounding Box (437, 119, 98, 246)\n",
      "Bounding Box (437, 114, 99, 245)\n",
      "Bounding Box (436, 126, 99, 248)\n",
      "Bounding Box (435, 129, 97, 242)\n",
      "Bounding Box (418, 144, 126, 238)\n",
      "Bounding Box (414, 146, 126, 230)\n",
      "Bounding Box (360, 194, 200, 199)\n",
      "Bounding Box (341, 232, 210, 148)\n",
      "Bounding Box (333, 233, 206, 139)\n",
      "Bounding Box (388, 257, 116, 116)\n",
      "Bounding Box (426, 267, 112, 95)\n",
      "Bounding Box (280, 272, 221, 97)\n",
      "Bounding Box (407, 283, 117, 81)\n",
      "Bounding Box (370, 274, 173, 99)\n",
      "Bounding Box (298, 289, 196, 103)\n",
      "Bounding Box (366, 288, 174, 98)\n",
      "Bounding Box (367, 286, 165, 104)\n",
      "Bounding Box (367, 287, 156, 100)\n",
      "Bounding Box (372, 284, 173, 98)\n",
      "Bounding Box (372, 284, 203, 99)\n",
      "Bounding Box (429, 279, 23, 101)\n",
      "Bounding Box (303, 259, 223, 123)\n",
      "Bounding Box (384, 265, 113, 105)\n",
      "Bounding Box (315, 259, 221, 119)\n",
      "Bounding Box (374, 263, 125, 117)\n",
      "Bounding Box (375, 244, 153, 128)\n",
      "Bounding Box (376, 245, 152, 127)\n",
      "Bounding Box (392, 233, 136, 117)\n",
      "Bounding Box (388, 232, 147, 116)\n",
      "Bounding Box (472, 121, 121, 229)\n",
      "Bounding Box (473, 136, 116, 231)\n",
      "Bounding Box (472, 145, 133, 219)\n",
      "Bounding Box (472, 143, 132, 221)\n",
      "Bounding Box (471, 158, 142, 211)\n",
      "Bounding Box (470, 155, 140, 214)\n",
      "Bounding Box (475, 182, 161, 195)\n",
      "Bounding Box (473, 181, 158, 202)\n",
      "Bounding Box (474, 184, 154, 197)\n",
      "Bounding Box (471, 179, 155, 199)\n",
      "Bounding Box (470, 179, 153, 201)\n",
      "Bounding Box (470, 170, 119, 221)\n",
      "Bounding Box (449, 182, 98, 228)\n",
      "Bounding Box (446, 224, 101, 183)\n",
      "Bounding Box (411, 156, 105, 229)\n",
      "Bounding Box (409, 156, 103, 229)\n",
      "Bounding Box (414, 152, 94, 222)\n",
      "Bounding Box (416, 153, 93, 221)\n",
      "Bounding Box (419, 160, 91, 217)\n",
      "Bounding Box (373, 175, 87, 213)\n",
      "Bounding Box (361, 176, 94, 215)\n",
      "Bounding Box (320, 190, 113, 216)\n",
      "Bounding Box (318, 187, 104, 219)\n",
      "Bounding Box (278, 194, 111, 204)\n",
      "Bounding Box (274, 195, 108, 198)\n",
      "Bounding Box (244, 195, 128, 202)\n",
      "Bounding Box (245, 195, 126, 202)\n",
      "Bounding Box (245, 192, 126, 205)\n",
      "Bounding Box (258, 204, 122, 191)\n",
      "Bounding Box (258, 205, 119, 188)\n",
      "Bounding Box (308, 270, 100, 140)\n",
      "Bounding Box (321, 266, 111, 148)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                           mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                           mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))\n",
    "                \n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                print(\"Bounding Box\",hand_bbox)\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                height, width, _ = image.shape\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                           mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                           mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))\n",
    "                \n",
    "                # Check which finger is at the top\n",
    "                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                \n",
    "                if thumb_tip.y < index_finger_tip.y:\n",
    "                    top_finger = \"Thumb\"\n",
    "                    top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                    base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "                else:\n",
    "                    top_finger = \"Index Finger\"\n",
    "                    top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                    base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP]\n",
    "\n",
    "                # Calculate angle with the top finger\n",
    "                angle = math.degrees(math.atan2(top_tip.y - base_tip.y, top_tip.x - base_tip.x))\n",
    "                \n",
    "                # Draw angles on the image\n",
    "                if top_finger == \"Thumb\":\n",
    "                    cv2.putText(image, f\"Angle with Thumb: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                elif top_finger == \"Index Finger\":\n",
    "                    cv2.putText(image, f\"Angle with Index Finger: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(image, \"Wrong Finger\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                \n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                height, width, _ = image.shape\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                           mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                           mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))\n",
    "                \n",
    "                # Check if wrist is straight with vertical\n",
    "                wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "                angle_with_vertical = math.degrees(math.atan2(wrist.y - middle_finger_tip.y, wrist.x - middle_finger_tip.x))\n",
    "                \n",
    "                # Proceed with angle calculation only if wrist is straight with vertical\n",
    "                if 80 <= angle_with_vertical <= 100:\n",
    "                    # Check which finger is at the top\n",
    "                    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                    if thumb_tip.y < index_finger_tip.y:\n",
    "                        top_finger = \"Thumb\"\n",
    "                        top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                        base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "                    else:\n",
    "                        top_finger = \"Index Finger\"\n",
    "                        top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                        base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP]\n",
    "\n",
    "                    # Calculate angle with the top finger\n",
    "                    angle = math.degrees(math.atan2(top_tip.y - base_tip.y, top_tip.x - base_tip.x))\n",
    "                    \n",
    "                    # Draw angles on the image\n",
    "                    if top_finger == \"Thumb\":\n",
    "                        cv2.putText(image, f\"Angle with Thumb: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    elif top_finger == \"Index Finger\":\n",
    "                        cv2.putText(image, f\"Angle with Index Finger: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(image, \"Wrong Finger\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.putText(image, \"Please straighten your wrist\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                \n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                height, width, _ = image.shape\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Calculate wrist and finger angles only if distance is between 100 to 120 pixels\n",
    "                        if 100 <= distance <= 120:\n",
    "                            # Check if wrist is straight with vertical\n",
    "                            wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                            middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "                            angle_with_vertical = math.degrees(math.atan2(wrist.y - middle_finger_tip.y, wrist.x - middle_finger_tip.x))\n",
    "\n",
    "                            # Proceed with angle calculation only if wrist is straight with vertical\n",
    "                            if 80 <= angle_with_vertical <= 100:\n",
    "                                # Check which finger is at the top\n",
    "                                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                                if thumb_tip.y < index_finger_tip.y:\n",
    "                                    top_finger = \"Thumb\"\n",
    "                                    top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                                    base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "                                else:\n",
    "                                    top_finger = \"Index Finger\"\n",
    "                                    top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                                    base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP]\n",
    "\n",
    "                                # Calculate angle with the top finger\n",
    "                                angle = math.degrees(math.atan2(top_tip.y - base_tip.y, top_tip.x - base_tip.x))\n",
    "\n",
    "                                # Draw angles on the image\n",
    "                                if top_finger == \"Thumb\":\n",
    "                                    cv2.putText(image, f\"Angle with Thumb: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                                elif top_finger == \"Index Finger\":\n",
    "                                    cv2.putText(image, f\"Angle with Index Finger: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                                else:\n",
    "                                    cv2.putText(image, \"Wrong Finger\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                            else:\n",
    "                                cv2.putText(image, \"Please straighten your wrist\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                           mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                           mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))\n",
    "                \n",
    "                # Check if wrist is straight with vertical\n",
    "                wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "                angle_with_vertical = math.degrees(math.atan2(wrist.y - middle_finger_tip.y, wrist.x - middle_finger_tip.x))\n",
    "                \n",
    "                # Proceed with angle calculation only if wrist is straight with vertical\n",
    "                if 80 <= angle_with_vertical <= 100:\n",
    "                    # Check which finger is at the top\n",
    "                    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                    if thumb_tip.y < index_finger_tip.y:\n",
    "                        top_finger = \"Thumb\"\n",
    "                        top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                        base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "                    else:\n",
    "                        top_finger = \"Index Finger\"\n",
    "                        top_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                        base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP]\n",
    "\n",
    "                    # Calculate angle with the top finger\n",
    "                    angle = math.degrees(math.atan2(top_tip.y - base_tip.y, top_tip.x - base_tip.x))\n",
    "                    \n",
    "                    # Draw angles on the image\n",
    "                    if top_finger == \"Thumb\":\n",
    "                        cv2.putText(image, f\"Angle with Thumb: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    elif top_finger == \"Index Finger\":\n",
    "                        cv2.putText(image, f\"Angle with Index Finger: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(image, \"Wrong Finger\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.putText(image, \"Please straighten your wrist\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                \n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                height, width, _ = image.shape\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize the TTS engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set voice rate\n",
    "engine.setProperty('rate', 150)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Calculate wrist and finger angles only if distance is between 100 to 150 pixels\n",
    "                        if 100 <= distance <= 200:\n",
    "                            # Check if wrist is straight with vertical\n",
    "                            wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                            middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "                            angle_with_vertical = math.degrees(math.atan2(wrist.y - middle_finger_tip.y, wrist.x - middle_finger_tip.x))\n",
    "                            # normalize the angle to be between 0 and 180 degrees and check if it's within 85 to 105 degrees\n",
    "                            angle_with_vertical = abs(angle_with_vertical) % 180\n",
    "                            # Proceed with angle calculation only if wrist is straight with vertical\n",
    "                            if  48 <= angle_with_vertical <= 105:\n",
    "                                # Check which finger is at the top\n",
    "                                # cv2.putText(image, f\"Angle : {angle_with_vertical:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                                ring_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "                                pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "                                # check which finger is at the top and set the top finger\n",
    "                                top_finger = None\n",
    "                                top_tip = None\n",
    "                                if thumb_tip.y < index_finger_tip.y and thumb_tip.y < middle_finger_tip.y and thumb_tip.y < ring_finger_tip.y and thumb_tip.y < pinky_tip.y:\n",
    "                                    top_finger = \"Thumb\"\n",
    "                                    top_tip = thumb_tip\n",
    "                                elif index_finger_tip.y < thumb_tip.y and index_finger_tip.y < middle_finger_tip.y and index_finger_tip.y < ring_finger_tip.y and index_finger_tip.y < pinky_tip.y:\n",
    "                                    top_finger = \"Index Finger\"\n",
    "                                    top_tip = index_finger_tip\n",
    "                                elif middle_finger_tip.y < thumb_tip.y and middle_finger_tip.y < index_finger_tip.y and middle_finger_tip.y < ring_finger_tip.y and middle_finger_tip.y < pinky_tip.y:\n",
    "                                    top_finger = \"Middle Finger\"\n",
    "                                    top_tip = middle_finger_tip\n",
    "                                elif ring_finger_tip.y < thumb_tip.y and ring_finger_tip.y < index_finger_tip.y and ring_finger_tip.y < middle_finger_tip.y and ring_finger_tip.y < pinky_tip.y:\n",
    "                                    top_finger = \"Ring Finger\"\n",
    "                                    top_tip = ring_finger_tip\n",
    "                                else:\n",
    "                                    top_finger = \"Pinky\"\n",
    "                                    top_tip = pinky_tip\n",
    "                                \n",
    "                                base_tip = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                                # Calculate angle with the top finger\n",
    "                                angle = math.degrees(math.atan2(top_tip.y - base_tip.y , top_tip.x - base_tip.x))\n",
    "\n",
    "                                # Draw angles on the image\n",
    "                                if top_finger == \"Thumb\":\n",
    "                                    cv2.putText(image, f\"Angle with Thumb: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                                elif top_finger == \"Index Finger\":\n",
    "                                    cv2.putText(image, f\"Angle with Index Finger: {angle:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                                else:\n",
    "                                    cv2.putText(image, \"Wrong Finger\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                            else:\n",
    "                                # Speak command to straighten the wrist\n",
    "                                engine.say(\"Please straighten your wrist\")\n",
    "                                engine.runAndWait()\n",
    "                        else:\n",
    "                            # Speak command to move hand closer to the face\n",
    "                            engine.say(\"Please move your hand closer to your face\")\n",
    "                            engine.runAndWait()\n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "def speak(text):\n",
    "    print(text)\n",
    "    engine = pyttsx3.init()\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[1].id)\n",
    "    engine.setProperty('rate', 150)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def async_speak(text):\n",
    "    threading.Thread(target=speak, args=(text,), daemon=True).start()\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "prev_thumb_angle = None\n",
    "prev_index_angle = None\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands, mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Hand detections\n",
    "        hand_results = hands.process(image)\n",
    "        \n",
    "        # Face detections\n",
    "        face_results = face_detection.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Hand detections\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                landmarks = np.array([[lm.x * width, lm.y * height] for lm in hand_landmarks.landmark])\n",
    "                hand_bbox = cv2.boundingRect(landmarks.astype(np.float32))\n",
    "                \n",
    "                # Draw bounding box around hand\n",
    "                cv2.rectangle(image, (int(hand_bbox[0]), int(hand_bbox[1])), \n",
    "                              (int(hand_bbox[0]+hand_bbox[2]), int(hand_bbox[1]+hand_bbox[3])), \n",
    "                              (0, 255, 0), 2)\n",
    "                \n",
    "                # Extract tip of the hand (assuming it's at the bottom when held vertically)\n",
    "                tip_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                \n",
    "                # Convert tip landmark to image coordinates\n",
    "                tip_x = int(tip_landmark.x * width)\n",
    "                tip_y = int(tip_landmark.y * height)\n",
    "                \n",
    "                # Hand position\n",
    "                hand_position = (tip_x, tip_y)\n",
    "                \n",
    "                # Face detections\n",
    "                if face_results.detections:\n",
    "                    for detection in face_results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        \n",
    "                        # Convert normalized bounding box coordinates to pixels\n",
    "                        ih, iw, _ = image.shape\n",
    "                        bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                               int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                        \n",
    "                        # Draw bounding box around face\n",
    "                        cv2.rectangle(image, bbox, (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Face position (considering the center of the bounding box)\n",
    "                        face_position = (bbox[0] + bbox[2] // 2, bbox[1] + bbox[3] // 2)\n",
    "                        \n",
    "                        # Calculate distance between hand tip and face position\n",
    "                        distance = math.sqrt((hand_position[0] - face_position[0])**2 + (hand_position[1] - face_position[1])**2)\n",
    "                        \n",
    "                        # Display distance on the image\n",
    "                        # cv2.putText(image, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Calculate wrist and finger angles only if distance is between 100 to 150 pixels\n",
    "                        if 100 <= distance <= 200:\n",
    "                            # Check if wrist is straight with vertical\n",
    "                            wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                            middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "                            angle_with_vertical = math.degrees(math.atan2(wrist.y - middle_finger_tip.y, wrist.x - middle_finger_tip.x))\n",
    "                            # normalize the angle to be between 0 and 180 degrees and check if it's within 85 to 105 degrees\n",
    "                            angle_with_vertical = abs(angle_with_vertical) % 180\n",
    "                            # Proceed with angle calculation only if wrist is straight with vertical\n",
    "                            if  48 <= angle_with_vertical <= 105:\n",
    "                                # Check which finger is at the top\n",
    "                                # cv2.putText(image, f\"Angle : {angle_with_vertical:.2f} degrees\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                                ring_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "                                pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "                                # Calculate angles with vertical for thumb and index finger\n",
    "                                thumb_angle = math.degrees(math.atan2(thumb_tip.y - wrist.y, thumb_tip.x - wrist.x))\n",
    "                                index_angle = math.degrees(math.atan2(index_finger_tip.y - wrist.y, index_finger_tip.x - wrist.x))\n",
    "\n",
    "                                # Check if thumb and index finger are bent based on the angle thresholds\n",
    "                                thumb_bent = abs(thumb_angle - prev_thumb_angle) > 10 if prev_thumb_angle is not None else False\n",
    "                                index_bent = abs(index_angle - prev_index_angle) > 10 if prev_index_angle is not None else False\n",
    "\n",
    "                                # Update previous angles\n",
    "                                prev_thumb_angle = thumb_angle\n",
    "                                prev_index_angle = index_angle\n",
    "\n",
    "                                # Speak if thumb or index finger is bent\n",
    "                                if thumb_bent:\n",
    "                                    async_speak(\"Thumb is bent!\")\n",
    "                                elif index_bent:\n",
    "                                    async_speak(\"Index finger is bent!\")\n",
    "                            else:\n",
    "                                async_speak(\"Please keep your wrist straight with vertical\")\n",
    "                        else:\n",
    "                            async_speak(\"Please keep your hand closer to the face\")\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
